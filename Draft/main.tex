\documentclass[11pt,a4paper]{article}

\usepackage{preamble}

\title{A Brickwall Model for de Sitter Black Holes}
\author{José Manuel Begines Sánchez}

\begin{document}

\input{00-titlepage.tex}

\tableofcontents

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}\label{label1}

Along with Quantum Mechanics, General Relativity (GR) has been one of the most notorious advances in Fundamental Physics of all time. It is a framework that, after being tested over and over again, has proven to be a very robust theory to explain the macroscopic universe we live in, from predicting how a celestial body will move through space-time, to even explaining how our universe developed into its current state. However, as the reader maybe be familiar with, there are still some problems to be solved within the predictions of GR. The most noticeable one is the fact GR predicts singular spacetimes, i.e. spacetimes with infinite curvature at certain points known as singularities, like black holes (BHs).

The appearance of these singularities are usually confronted saying that GR is a classical theory, and that in places like the center of a BH the energy density is so high that Quantum Mechanics needs to be taken into account. Here is where one faces the first problem: up until today, we do not have a unique consistent Quantum Theory of Gravity that can explain our universe.

Through the years, there has been semi-classical approaches to help us extract quantum properties from BHs. In 1972, Jacob Bekenstein, based on the works of Demetrios Christodoulou and Stephen Hawking who proved that the area of a BH event horizon could not shrink but to grow or (in a few particular cases) remain the same \cite{Hawking:1971tu,Christodoulou:1971pcn}, proposed that we could associate an entropy to a BH proportional\footnote{Today we know that this proportionality factor must be 1/4 to maintain self consistency with the first law of thermodynamics} to this area:

\begin{equation}\LA{SBH}
    S_{BH}\propto \frac{k_B}{l_P^2}A ~~~~:~~~~ l_P=\left(\frac{\hbar G}{c^3}\right)^{1/2}
\end{equation}

Where $l_P$ is known as Planck's constant expressed in terms of the fundamental constants $G$,$\hbar$ and $c$; and $k_B$ is Boltzmann's constant. 

From this idea, later on, Stephen Hawking \cite{Hawking:1975vcx} proved that BHs must emit a faint radiation\footnote{So faint that up until today we do not have sufficiently high detecting ability to sense it} with the spectrum of a black body whose temperature is derived from equation (\ref{SBH}). For example, in the case of the Schwarzschild BH:

\begin{equation}
	T = \left(\frac{\partial U}{\partial S}\right)_V = \frac{4l_P^2c^2}{k_B}\frac{dM}{dA} = \frac{l_P^2c^6}{8\pi k_BG^2M} = \frac{\hbar c^3}{8\pi k_B GM}
\end{equation}

This radiation would make the BH lose energy and ultimately evaporate. Indeed, this process has led to one of the biggest recent puzzles in theoretical physics: the information loss paradox \cite{Hawking:1976ra}. In a few words, matter in a pure state may be thrown into a BH, but only thermal radiation comes out. This would imply however, that a pure state has evolved into a mixed state, which would violate unitarity. This has lead physicists nowadays to think that well established principles, as unitarity or even locality, may be abandoned.

Also, by that time, John Wheeler had already postulated, one the most important theorems in BHs physics, No-Hair Theorem.

\begin{boxedminipage}{0.9\textwidth}
    \textbf{No-hair Theorem: }
    
    All stationary BH solutions of the Einstein-Maxwell equations of gravitation and electromagnetism in general relativity can be completely characterized by only three independent externally observable classical parameters: mass, angular momentum, and electric charge.
\end{boxedminipage}

Taking all of these considerations into account, it is quite straight forward then to consider a BH as a macroscopic thermodynamic system with its few macroscopic degrees of freedom. However this still leave us with quite a few questions. First of all we have the fact that entropy as we know it is an extensive property, but if this is the case, then why is it proportional to the area of the event horizon, rather than the volume it encloses? What's more, one must also deal with the statistical mechanics part of thermodynamics. That is, entropy is a measure of the volume of the phase space of a system constrained by macroscopic properties, the more microscopic configurations are compatible with the macroscopic properties the more entropy our system will have. However, as we already mentioned, BHs are uniquely fixed by their macroscopic properties, i.e, their phase space is zero dimensional. If this is the case, then, what could we understand as this microstates whose ensemble average gives us the BH macrostate?

The first question has been considered a hint for a fundamental and general property of quantum gravity theories, first proposed by Gerard't Hooft and later promoted by Leonard Susskind by 1994 \cite{Susskind_1995}, the holographic principle.

\begin{boxedminipage}{0.9\textwidth}
    \textbf{Holographic Principle: }
    
    Quantum Gravitational Theories must be holographic. That is, any (d+1)-dimensional gravitational theory should have a description in terms of d-dimensional quantum field theory without gravity.
\end{boxedminipage}

This statement has found realization with the AdS/CFT correspondence, conjectured by Juan Maldacena in 1997 \cite{Maldacena_1999}, which although not being proved yet, has worked like a charm in every tested example.

\begin{boxedminipage}{0.9\textwidth}
    \textbf{AdS/CFT Correspondence Conjecture: }
    
    A (d+1)-dimensional anti-de Sitter spacetime can be described in terms of a d-dimensional conformal field theory.
\end{boxedminipage}

Even though the AdS/CFT correspondence, as I already pointed out, has proven to work quite well, it most likely cannot be applied in our universe to obtain a description of quantum gravity whatsoever, as most astronomical observations points towards our universe being de Sitter. This encompass a whole new problem on its own, since there is still no consensus in what kind of theory is dual to de-Sitter spacetimes or how this duality manifest itself (See \cite{Galante:2023uyf} for a recent review on de-Sitter holography). Finding it would entail an enormous boost in the field of Quantum Gravity.

Now, we still have to discuss the second question we mentioned. What are these BH microstates? From string theory, there exist one major candidate: Fuzzballs. 

This \textquotedblleft Fuzzball proposal\textquotedblright~ states there exists $e^{S}$ horizon-free, non-singular solutions, known as Fuzzballs, which globally look like the BH, but differ from it up to the horizon-scale, i.e, the interior of the BH gets replaced by something different. The BH would come out as the average of an ensemble of these Fuzzballs. The singularity and the event horizon would come up as a by product of considering the classical limit in the average process.

This proposal can be very appealing, because if this were the case, it would solve information paradox. If there is no horizon, there is no information loss. Matter would get inside and at some point it would escape. Information would dilute, there's no doubt of that, but would still be there.

In the context of everything we have discussed so far, one can argue that BHs must be fast scramblers, i.e. they dilute the information they get very fast\footnote{It would happen in time $t\sim \log d$ where d is the dimension of the Hilbert Space we would be dealing with \cite{Sekino_2008}}. This fast scrambling is a characteristic property of Quantum Chaos and Random Matrix Theory (RMT) (See Section \ref{PRELIM})

One then, would like to see if this Fuzzballs reproduce this RMT-like behaviour. However, testing this kind of behaviour has proven to be very challenging \cite{Das_2023}. That's what has lead different authors \cite{Das_2023,Jeong_2025,das2023fuzzballsrandommatrices,das2023brickwallrotatingbtzdiprampplateau,das2025brickwalladsschwarzschildblack} to consider a \textquotedblleft Fuzzball Toy model\textquotedblright, a Brickwall model to be more precise, that could serve as a way to detect some hint of RMT behaviour. And, indeed this has been the case, the normal modes of scalar and fermionic fields has shown evidence of Quantum Chaotic features by different probes: level-repulsion, the dip-ramp-plateau structure of the Spectral Form Factor and the Krylov Complexity of these states.

This master thesis aims to used the techniques developed and the considerations taken into account in the mentioned studies performed over AdS spacetimes, and apply them on dS spacetimes to try to enhance our understanding of the quantum aspects of cosmological and BH spacetimes and hopefully shed a bit of more light on the holographic nature of de Sitter space. 

{\noindent\color{red} Once everything is finished, I will write here a brief summary of what I discuss in each part.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Preliminaries}\LA{PRELIM}
\subsection{Asymptotically de Sitter spacetimes}

The study of asymptotically de Sitter spacetimes, i.e spacetimes which \textquotedblleft looks like\textquotedblright an exact de Sitter spacetime in a certain limit, is mostly motivated by the fact that different astrophysical probes suggests that our Universe is expanding at an acclerated rate, which indicates that our cosmological constant is small, but positive \cite{2013PhR...530...87W}. This then indicates that if our universe, although not exactly de Sitter is tending towards this state in the future, when matter would have sufficiently diluted \cite{PhysRevD.28.2118}. 

Current measures of our cosmological constant not only indicates that it is positive but that it is too small, at least by current theoretical considerations. If one considers that the cosmological constant is the vacuum energy of the universe due to its matter and radiation content, then there exists a mismatch between theoretical prediction and observations by around 122 orders of magnitude. This constitute the worst fine-tuning problem of the history of physics, known as the cosmological constant problem.

Insights in the quantum features of spacetime might provide us a way of addressing this discrepancy. However, several there are still several obstacle in our way that has prevented us from doing so. One of the main complications is that, obtaining universes with positive cosmological in string theory has proven to be a truly challenging task.

Let's first review, the basic properties of the de Sitter (dS) spacetime. The dS spacetime, along with AdS and Minkowsky, is one of the three maximally symmetric spacetime, i.e which has the maximum number of allowed symmetries. The easiest way to visualize dS is through embedding. If we consider Minkowksi space time in (d + 2) dimensions $\calm^{d+2}$ with metric:

\begin{equation}
    ds^2_{\calm^{d+2}} = -\dd x_0^2 + ... + \dd x_{d+1}^2,
\end{equation}

{\noindent the $dS_{d+1}$ spacetime can be obtained as the hypersurface embedded in it, described by:}

\begin{equation}\LA{DS}
    -x_o^2+x_1^2+...+x_{d+1} = l^2
\end{equation}

{\noindent where $l$ defines the absulate scale in the $dS_{d+1}$ spacetime and is known as the cosmological horizon radius. This equation defines a hyperboloid in $\calm^{d+2}$, with its axis along the 0th direction. It is straightforward to see that the group that leaves unchanged (\ref{DS}) is the Lorentz group SO(d,1), which constitutes the group of isometries of $dS_{d+1}$. One key thing to note, that we will discuss later is that $SO(d+1,1)$ is isomorphic to the conformal group of the d-dimensional Eucliden space.}

This spacetime satisfies Einstein's field equation,

\begin{equation}
    R_{\mu\nu} - \frac{1}{2}R g_{\mu\nu} + \Lambda g_{\mu\nu} = 0
\end{equation}

{\noindent with a positive curvature given by:}

\begin{equation}
    \Lambda = \frac{d(d-1)}{2l^2}
\end{equation}

This spacetime can be described by different coordinates. If we want to map the whole manifold we can make use of the \textbf{Global coordinates} $\{\tau,\theta_i\}$. This coordinates are related to the embedding coordinates by:

\begin{equation}
    \left\{
        \begin{aligned}
            X^0 &= l\sinh\tau\\
            X^i &= l\cosh\tau \omega^i
        \end{aligned}
    \right.
\end{equation}

{\noindent where:}

\begin{equation}
    \begin{aligned}
        \omega^1 &= \cos\theta_1,\\
        \omega^2 &= \sin\theta_1\cos\theta_2,\\
                 &\vdots\\
        \omega^d &= \sin\theta_1...\sin\theta_{d-2}\cos\theta_{d},\\
        \omega^{d+1} &= \sin\theta_1...\sin\theta_{d-2}\sin\theta_{d},\\
    \end{aligned}
\end{equation}

{\noindent such that $\theta_i\in[0,\pi)$ for $1\leq i < d$ but $\theta_d\in[0,2\pi$ which constitute the coordinates of an $S^d$ sphere and $\tau\in(-\infty,+\infty)$. In this coordinates the metric takes the following form:}

\begin{equation}
    \frac{\dd s^2}{l^2} = -\dd\tau^2 + \cosh^2\tau \dd\Omega_d^2
\end{equation}

{\noindent, where $\dd \omega_d^2$ is the metric of the d-sphere $S^d$. For $\tau>0$ this metric gives us the usual visualisation of a bounded Universe whose size is expanding exponentially as time evolves forward.}

This coordinates are not well fitted to study the causal structure of the dS. For such purpose we can define a conformal time $T$ such that:

\begin{equation}
    \cos T = \frac{1}{\cosh\tau} ~~~:~~~ T\in[-\pi/2,\pi/2]
\end{equation}

{\noindent so that the metric takes the following form:}

\begin{equation}
    \frac{\dd s^2}{l^2} = \frac{1}{\cos^2 T}\left(-\dd T^2 + \dd\theta_1^2 +\cos^2\theta_1\dd\Omega_{d-1}^2\right)
\end{equation}

This then allow us to represent the Penrose Diagram in Figure \ref{PENROSE}, where $I^\pm$ represents the infinite future and past respectively at $T=\pm\pi/2$ and we name $\theta_1=\pm \pi/2$ North and South pole respectively. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.5\linewidth]{figs/PENROSE.eps}
    \caption{Penrose diagram of the dS spacetime considering the timelike coordinate T in the vertical direction. A horizontal slice represents an $S^d$ and each point would be an $S^{d-1}$, with radius $1/\cos T$. The dashed lines represent the light rays that goes through the origin. Image taken from \cite{spradlin2001leshoucheslecturessitter}}
    \label{PENROSE}
\end{figure}

Light rays travel at $45\degree$ so if one light ray is emitted from the north pole at infinite past the would only be able to reach the south pole in the infinite future. This is a clear indication of the fact that no single observer has access to the full spacetime. Consequently, we would like to have a set of coordinates that describe the region of $dS$ accessible to a single observer. This region would be the intersection between the region that can be affected by an observer. If we consider this observer being in the North Pole\footnote{Note that this is an arbitrary choice, the North Pole can be any horizontal slice just by reparametrization of the $\theta_1$ coordinate}, then this region would be the left triangle in Figure $\ref{PENROSE2}$ which we commonly refer to as the \textbf{Static Patch}.

This region is described in terms of its own coordinates $\{t,r,\theta_i\}$ which are related to the embedding coordinates by:

\begin{equation}
    \left\{
        \begin{aligned}
            x^0 &= \sqrt{l^2-r^2}\sinh t, \\
            x^i &= r\omega^i, ~~~~~\text{for }1\leq i <d+1,\\
            x^{d+1} &= \sqrt{l^2-r^2}\cosh t,
        \end{aligned}
    \right.
\end{equation}

From which the dS metric takes the form of the so-called static patch metric:

\begin{equation}
    \dd s^2 = -(l^2-r^2)\dd t^2 + \frac{\dd r^2}{l^2-r^2} + r^2\dd\Omega^2_{d-1} ~~~~:~~~~ r\in[0,1)
\end{equation}

We can highlight several properties of this metric. First of all, as one can infer from the name, this metric is static, in the sense that it does not depend on the timelike coordinate, which implies that $\partial_t$ is a timelike Killing vector. Additionally, at $r=l$ we encounter the event horizon where the timelike Killing vectors become null. 

It is noteworthy that, the appearance of the cosmological horizon is not a consequence of a certain accumulation of matter, the dS spacetime is a vacuum solution, or singularity, rather than the accelerated expansion of the dS spacetime and the finiteness of the speed of light. 

Note that we have defined the static patch in terms of a particular observer. Consequently, each different observer would have a different cosmological horizon. This differs completely from BH event horizons, which is the same independently of the considered observer.

\begin{figure}[ht]
    \centering
    \subcaptionbox{}
    {
    \includegraphics[width=0.3\linewidth]{figs/static_1.pdf}
    }
    \subcaptionbox{}
    {
    \includegraphics[width=0.3\linewidth]{figs/static_2.pdf}
    }
    \subcaptionbox{}
    {
    \includegraphics[width=0.3\linewidth]{figs/static_3.pdf}
    }
    \caption{The junction of the region that can affect the observer and the one that can be affected by the observer. Images taken from \cite{Galante:2023uyf}}\label{PENROSE2}
\end{figure}

This horizon, following from the study started in 1977 by Gibbons and Hawking \cite{PhysRevD.15.2738,PhysRevD.15.2752}, has a temperature and an entropy which must obey an area law. The temperature takes the following form which depends only on the cosmological horizon radius:

\begin{equation}
    T_{ds}=\frac{\hbar c}{2\pi k_B l}
\end{equation}

But, wouldn't this then imply that the cosmological horizon radiates and consequently would eventually evaporate? Considering that this cannot be the case in dS, it has to be the case that the Hawking radiation is in thermal equilibrium with its surrounding so that the overall energy exchange cancels out, similarly to the eternal BHs in AdS.

The entropy is calculated following an semiclassical approach with the Eulidean path integral \cite{PhysRevD.15.2752}:

\begin{equation}
    Z = \int Dg \exp\left(-I_E[g]\right) ~~~;~~~ I_E[g] = -\frac{1}{16\pi G_N}\int d^4 x_E \sqrt{g}(R-2\Lambda)
\end{equation}

Where the Einstein-Hilbert action integral is performed over the Euclidean coordinates, i.e. $t_E=it$. As it is commonly known \cite{gibbons_path_1978}, the gravitational path integral diverges and is not well defined. However, by a saddle point approximation, using the on-shell action one can directly obtain the area law for the dS entropy\footnote{In the case of Schwarzschild BH for example for this process one needs to consider boundary and regularisation terms but not in this case. See the details in the Appendix A of \cite{Galante:2023uyf}}:

\begin{equation}
    S_{GH} = \frac{k_Bc^3A_H}{4\hbar G_N}
\end{equation}

However, what is the microscopic origin (if it really has one) of this formula. This area law also points towards considering a duality between dS and a certain field theory which would live on the horizon as in the case of AdS/CFT. Previously, I mentioned that the isometry group of $dS_{d+1}$ was the conformal group of $\mathds{R}^d$, which made the principal proposal for this field theory is to be an Euclidean CFT.

Following from the existence of the cosmological horizon it has already been proposed that dS spacetimes must be fast scramblers \cite{Geng_2021} like black holes and must dilute information very fast. If this were to be the case, then the system must show signatures of Quantum Chaotic behaviour (See following section), which is what this work is going to probe.

\subsection{Random Matrix Theory: Diagnostics of quantum chaos}

From the classical point of view, although no universally accepted mathematical definition of Chaos exists, we have an intuitive senses of what it means. In a few words, we can say that a system is chaotic if it is \textquotedblleft very sensitive to initial conditions\textquotedblright. Although chaotic dynamics are that generic, thre is a class of systems 
for which dynamics are not chaotic, known as integrable systems. Indeed, if we consders a classical system with N degrees of freedom with a Hamiltonian in terms of cannonical coordinates and momenta $H(\mathbf{p},\mathbf{q})$, one can say that this system is integrable if it has as many functionally independent conserved quantities $\mathbf{I}=\left(I_1,...,I_N\right)$ as degrees of freedom. This can be expressed as:

\begin{equation}
    \left\{I_j,H\right\}=\left\{I_j,I_k\right\} = 0, ~~~~\text{where}~~~\left\{g,h\right\} = \sum^N\frac{\del g}{\del q_j}\frac{\del h}{\del p_j} - \frac{\del g}{\del p_j}\frac{\del h}{\del q_j}
\end{equation}

Figure \ref{Example_Chaos}, is a good example where one can see the difference between integrable (a) and chaotic systems (b). The first system is symetric under time traslation and 2D-rotations, so following Noether's Theorem \cite{Noether_1971}, Energy and Angular Momenta is conserved, which makes the the system non-chaotic as one can easily infer from the trajectories. On the other hand, if one considers the second system we have lost 2D-rotations symetry, so in this case only Energy is conseved. This inexistance of a second conserved quantity then leave us with a chaotic system in which if one minimally perturbes initial conditions it can be seen that after a certain scale of time, trajectories become uncorrelated.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\linewidth]{figs/Stoe_billiards.jpg}
    \caption{Each line represent examples of trajectories of a particle bouncing in a cavity with perfectly elastic collisions: (a) Circular shaped, non-chaotic; (b) Stadium shaped, chaotic. Image taken from scholarpedia \cite{stockmann2010microwave}}
    \label{Example_Chaos}
\end{figure}

Considering this one could may well be in interested in studying the concept of chaos in quantum systems. However, it was clear since the early days of quantum mechanics that the classical notion of chaos could not be directly applied to quantum systems for different reasons. First of all, as Schrödinger's equation is linear, it cannot have exponentially departing trajectories for wave functions (the overlap between two different quantum states that evolve with the same Hamiltonian will not vary). Additionally, although one can use quantum mechanic formulations based on the phases-space, "trajectories" do not exist in quantum mechanics and consequently you cannot specify the phase-space initial conditions as position and momenta cannot be specified simultaneously. This then brings up the question of what is the analogue of chaotic motion in quantum systems.

In the early days of quantum mechanics, integrable systems were prety much understood, based on Bohr's initial insight. Along allowed trejectories withing quantum mechanics, the classical action must satisfy the quantization condition:

\begin{equation}
    \oint p\dd q =2\pi\hbar n,
\end{equation}

i.e, it must be quantized in units of $\hbar$, a conjecture which ended up being formalized in terms of the WKB approximation \cite{wentzel_verallgemeinerung_1926,kramers_wellenmechanik_1926,Brillouin:1926blg}. However, chaotic systems remained a mystery for a very long time, mostly due to the fact that it was not clear how one could quantize classical chaotic trajectories, which were not closed in phase space. Some people attempted to resolve these problems, even Einstein wrote a paper about it in 1917 \cite{stone_einsteins_2005}. However, time went by and it wasn't until the 70s when Gutzwiller work \cite{gutzwiller_periodic_1971} brought these issues into focus of lots of research that fell under the name of the title quantum chaos. Up to this day, nonetheless there many question that need solving, including a precise definition of what do we really mean by quantum chaos.

The most crucial results that lay the foundation on which quantum chaos builds came from works of Wigner and Dyson \cite{wigner_statistical_1951,wigner_characteristic_1955,wigner_characteristics_1957,wigner_distribution_1958,dyson_statistical_1962}, with the help of Mehta \cite{mehta_statistical_1960}, Gaudin \cite{mehta_density_1960}, Porter \cite{porter_statistical_1965} and many others. They developed a theory to help them understand the spectra of complex atomic nuclei, known as Random Matrix Theory (RMT) and in an important discovery in 1984 \cite{bohigas_characterization_1984}, it was found that RMT was applicable to quantum chaotic systems, i.e, quantum systems whose classical counterparts are chaotic.
The original idea that lead Wigner to this theory, was realizing that trying to predict exact energy levels and their corresponding eigenstates in complex systems was too difficult. Conversely, the correct approach was to study the statistical properties of said spectrum. Secondly, he also realised that if one looks into energy window sufficiently small, so that the density of states is approximately constant, then the Hamiltonian, in a general basis, would look essentially like a random matrix. Following this idea, then, if one studies the statistical properties of random matrices, subject to the symmetries of the Hamiltonian of interest, we could gain insight on the statistical properties of energy levels and eigenstates of complex systems.

This insight was very revolutionary and incredibly counter-intuitive. Let's just stop to think about it, when one try to diagonalize many-body physical Hamiltonians, one usually expresses it in a special basis in which the resulting matrix is simplified and its non-zero elements are anything but random. This, however does not go against Wigner's idea where one deals with a general basis.

In general, RMT deal with a general ensemble of matrices however, where the joint probability distribution (jpd) of the N-dimensional matrix elements of H (where H would be a realisation of this ensemble) would take the following form:

\begin{equation}\LA{JPD_MATRIX}
    P(A) = C\exp{\left[-\beta\text{tr}V(H)\right]},
\end{equation}

where V(H) is a positive-function of H, and C is the normalization constant \cite{pandey_quantum_2019}. However, for our purposes we consider the most extensively studied case, the Gaussian ensembles with $V(\xi)=\xi^2/4\upsilon^2$\footnote{This is of course a consequence of the central limit theorem}. This gives us the jpd of every single term, though as we are particularly interested in the eigenvalues of the matrix we can transform equation (\ref{JPD_MATRIX}), into the jpd of just the eigenvalues \cite{pandey_quantum_2019,martinez-azcona_decomposing_2025}:

\begin{equation}\LA{JPD_EIGEN}
    \rho_\beta\left(E_1,...,E_N\right) = C'\prod_{i<j}\left|E_i-E_j\right|^\beta \exp{\left[-\beta \sum_k V(E_k)\right]}
\end{equation}

Where, we are considering an unordered set of eigenvalues $\left\{E_k\right\}.$\footnote{Note that in general we will deal with Hamiltonians which are infinite dimensional and consequently have infinite, although countable, eigenvalues. However, as we already mentioned we are just gonna focus on small energy window.} Here, the $\beta$-parameter is also known as the Dyson index and controls the symmetries of the matrix we are considering and consequently differentiates between the 3 possible cases \cite{pandey_quantum_2019,dalessio_quantum_2016}:

\begin{itemize}
    \item Gaussian Orthogonal Ensemble (GOE, $\beta = 1$): In this ensemble the matrices are real and satisfy $H_{ij}=H_{ji}$. This type of Hamiltonians describe time-reversal invariant systems.
    \item Gaussian Unitary Ensemble (GUE, $\beta = 2$): In this ensemble the matrices are complex and satisfy $H_{ij}=H_{ji}^*$. This type of Hamiltonians describe systems where time reversal is violated.
    \item Gaussian Symplectic Ensemble (GSE, $\beta = 4$): In this ensemble the matrices are complex and satisfy $H_{ij}=J_{ik}H_{lk}J_{lj}$, where $J^{-1}$ is the symplectic matrix. This type of Hamiltonians describe time-reversal invariant, where the half-integer spin-rotation symmetry is broken.
\end{itemize}

\begin{figure}
    \centering
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[
                axis equal,
                width = 0.7\textwidth,
                height = 0.4\textwidth,
                xmin = -1.1,
                xmax = 1.1,
                ymin = 0,
                xtick = {-1,-0.5,0,0.5,1},
                samples = 200,
                domain = -1:1,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=E,
                ylabel=$\overline{\rho}(E)$]
                \addplot+ [draw=black, mark=none,line width =1]
                {2*(1-x^2)^(1/2)/2};
            \end{axis}
        \end{tikzpicture}
    \caption{Wigner semicircle law that describes the average density of eigenvalues in a Gaussian random matrix ensemble considering $R=1$}\LA{SEMICIRCLE}
\end{figure}



From the jpd in equation (\ref{JPD_EIGEN}), one can obtain the average density of eigenvalues, i.e the probability density of a single eigenvalue, which is defined as: 

\begin{equation}
    \overline{\rho}(E)=\int...\int \dd x_2...\dd x_N \rho_\beta(E,E_2,...,E_N)
\end{equation}

{\noindent This gives us the well-known Wigner's semicircle law, in the Gaussian case \cite{wigner_characteristic_1955} (See Figure \ref{SEMICIRCLE}):}

\begin{equation}\LA{SEMICIRCLE_EQ}
    \overline{\rho}(E) = \frac{2\sqrt{R^2-E^2}}{\pi R^2} ~~~~~ : ~~~~~ R^2 = 4\beta \upsilon^2 N
\end{equation}

Throughout this last section we addressed that the energy levels of chaotic systems follow a Wigner-Dyson distribution. But on the contrary, how are integrable systems characterized then? This was first addressed by Berry and Tabor in 1977 \cite{berry_level_1997}. In a few words, they just found that in integrable systems energy levels were uncorrelated, i.e, they should have a jpd of the same form as (\ref{JPD_EIGEN}) but without the productorium part. It would be just a multiplication of the different Gaussian distributions for each eigenvalue. This ensemble, is known as the \textit{Poisson} ensemble, a naming that can be better understood in the following section.

\subsubsection{Level Spacing Distribution}

Up until now, we have been just analyzing RMT as the mathematical theory it is. Let's now make a step further and consider the hypothesis that, as we already mentioned, says that the spectrum of Quantum Chaotic systems have the same statistics as the spectrum of random matrices of the Gaussian Ensemble. To attain this universality, in the case of short range relations, we need to tweak the eigenvalues we are working with. This, \textquotedblleft tweaking \textquotedblright is known as unfolding, and is essentially a rescaling of the eigenvalues. What this procedures ensures is that the average spacing between consecutive eigenvalues becomes 1 in the whole spectrum. The unfolding function\footnote{Note that this is just the mean cumulative density} is defined by \cite{pandey_quantum_2019}:

\begin{equation}\LA{UNF_FUNC}
    F(E) = N\int_{-\infty}^E \overline{\rho}(E')\dd E',
\end{equation}

{\noindent ,where if we consider the Gaussian case, i.e, equation (\ref{SEMICIRCLE_EQ}), we obtain:}

\begin{equation}
    F(E) = \frac{N}{\pi R^2}\left[E\sqrt{R^2-E^2}+R^2\sin^{-1}\left(\frac{E}{R}\right)\right]
\end{equation}

Then, our new spectrum would be $\xi_k = F(E_k)$ (for our incoming purposes, after unfolding we are gonna sort the eigenvalues so that and relabel so that $\xi_1<...<\xi_N$). It can be easily seen that with this redefinition of the spectrum (considering that the eigenvalues are sufficiently close) the mean separation between closest levels will be:

\begin{equation}
    \frac{\dd\xi}{\dd E} = N\overline{\rho}(E) 
\end{equation}

{\noindent and then the closest level separation would be:}

\begin{equation}
    s = \xi_{i+1}-\xi_i = F(\xi_{i+1})-F(\xi_i) \approx N(E_{i+1}-E_{i})\overline{\rho}(E_i) \approx 1
\end{equation}

{\noindent where in the last step we have considered the definition of probability density if both eigenstates are \textquotedblleft sufficiently close\textquotedblright.}

From this, now it can be calculated the closest neighbor spacing distribution $p_o(s)$, i.e, how the separation between closest neighbours is statistically distributed. The exact result was derived by Mehta \cite{mehta_random_2004}. However, this exact expression is a really cumbersome and Wigner already proved that could be easily approximated just with the N=2 case (See Appendix \ref{LSD}, for the derivation) \cite{wigner_statistical_1951}. The three different Gaussian ensembles are interpolated by the Wigner-Dyson distribution:

\begin{equation}\LA{WGDY}
    p_o(s) = a_\beta s^\beta \exp\left[-b_\beta s^2\right]
\end{equation}

{\noindent where:}

\begin{equation}
    a_\beta=2\frac{\Gamma\left[\frac{2+\beta}{2}\right]^{1+\beta}}{\Gamma\left[\frac{1+\beta}{2}\right]^{2+\beta}} ~~~~;~~~~ b_\beta=\frac{\Gamma\left[\frac{2+\beta}{2}\right]^{2}}{\Gamma\left[\frac{1+\beta}{2}\right]^{2}}
\end{equation}


{\noindent So, then, if we consider each particular case substituting $\beta$ in equation (\ref{WGDY}) would be:}

\begin{equation}
    \begin{aligned}
        p_0(s) &= \frac{\pi}{2}s\exp\left(-\frac{\pi}{4}s^2\right) , &\beta = 1 \text{ (GOE)}\\
        p_0(s) &= \frac{32}{\pi^2}s^2\exp\left(-\frac{4}{\pi}s^2\right) , &\beta = 2 \text{ (GUE)}\\
        p_0(s) &= \frac{2^{18}}{3^6\pi^3}s^4\exp\left(-\frac{64}{9\pi}s^2\right) , &\beta = 4 \text{ (GSE)}\\
    \end{aligned}
\end{equation}

{\noindent which are plotted in Figure \ref{SEP_DIST}. The main important feature that the 3 ensemble share is the fact that this distribution goes to 0 at s=0. This is known as level repulsion. This is a signature of the correlations between the different energy levels.}

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[width=0.7\textwidth,height=0.7*7/10*\textwidth,
                xmin=-0.05,
                xmax=4.05,
                ymin=0,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=s,
                ylabel=p(s),
                y label style = {rotate = -90}]
                \addplot [
                    green,
                    line width =1,
                    ]
                table {etc/data/GOE.dat};
                \addplot [
                    blue,
                    line width =1]
                table {etc/data/GUE.dat};
                \addplot [
                    red,
                    line width =1]
                table {etc/data/GSE.dat};
                \addplot [
                    black,
                    line width =1]
                table {etc/data/POISSON.dat};
                \legend{GOE,GUE,GSE,Poisson}
            \end{axis}
        \end{tikzpicture}
        \caption{Level spacing distributions of the GOE,GUE,GSE and Poisson ensembles (Green, Blue, Red, Black)}\LA{SEP_DIST}
\end{figure}

This level repulsion will not be present in the \textit{Poisson}, i.e, the integrable, case. If we consider this ensemble, then the unfolded spectrum will take the following form:

\begin{equation}
    \xi = F(E) = N \int_{-\infty}^E\exp{-\beta V(E)}\dd E'
\end{equation}

{\noindent and consequently the jpd of this new spectrum would be:}

\begin{equation}
    \widetilde{\rho}(\{\xi_1,...,\xi_N\}) \propto 1,
\end{equation}

{\noindent i.e, the unfolded spectrum would be uniformly distributed over the domain $[0,N]$. From this, now we can easily extract the level separation distribution. We just need to make the same considerations like in the problem of particle desintegration detection, where instead of time we consider energy level separation. Every energy level separation would be an independent and indentically distributed random variable on its own, and then the level separation distribution would be \textquotedblleft probability that a another energy level appears at a certain distance considering the constant probability that at a certain energy it exists an energy level\textquotedblright, i.e, the same we consider with particle detection, \textquotedblleft the probability that after after a certain time of having detected a desintegration, we detect another desintegration, considering that the probability that a desintegration occurs at a particular time is constant\textquotedblright. And then the distribution we must consider is the Poissonian (I hope this makes the naming of the ensemble clearer):}

\begin{equation}
    p_0(s)=\lambda e^{-\lambda s},
\end{equation}

{\noindent ,where if we keep following the analogy $\lambda$ is inverse of the \textquotedblleft mean time between desintegrations\textquotedblright, and as we want the mean separation between levels to be one, we need to fix $\lambda=1$. This distribution is also plotted in Figure \ref{SEP_DIST}. It is obvious, as I already mentioned, that level repulsion is no present in this case, which is something to be expected as the premise of this ensemble was that each energy level had no correlation whatsoever.}

In our system as is the case in \cite{Jeong_2025} we expect to have a parameter that if we vary continuously will transition our system from different stages of chaos to integrability. Wigner-Dyson distribution in equation (\ref{WGDY}) as we already discussed interpolates the three different distributions of the GOE, GUE and GSE, ensembles. However, we need a distribution that interpolates between this chaotic ensembles and the Poisson ensemble. To do so, we can make use of the Brody \cite{brody_statistical_1973} distribution that can interpolate between GOE and Poisson:

\begin{equation}
    p_o(s) = a_\beta s^\beta \exp\left[-b_\beta s^2\right]
\end{equation}

{\noindent where, the different parameters are defined by:}

\begin{equation}
    a_\beta=(1+\beta)\Gamma\left[\frac{2+\beta}{1+\beta}\right]^{1+\beta} ~~~~;~~~~ b_\beta=\Gamma\left[\frac{2+\beta}{1+\beta}\right]^{(1+\beta)}
\end{equation}


There is one last thing we need to consider. All the steps we have take so far have been over RMT, but what we want to do is to compare this statistics to the ones of our system of choice. But, if this is the case, how do we unfold the energy window we consider in our system, because in a general system we are not going to have a closed expression for $\overline{\rho}$, that we could insert in equation \ref{UNF_FUNC}. To do so, in our case we are gonna use a polynominal fitting. First of all we need to define a staircase function:

\begin{equation}
    F_{stair}(E) = \text{Number of eigenvalues}\leq E
\end{equation}

Then, we obtain a smooth fit with a nth degree polynomial $F_{fit}(E)\approx F_{stair}(E)$ which is meant to capture the global trend in the spectrum, and consider the unfolded spectrum to be $\xi_i = F_{fit}(E_i)$. It is important to note that we need to consider a small n, because if n is too high we could overfit the spectrum capturing the noise of the realisation. In our case we have considered $n=4$.

\subsubsection{Spectral Form Factor}

The previous Quantum Chaos probe we talked about, level separation density, dealt with short-range correlation, i.e, how the different energy levels that are close together affect one another. On the other hand, the following probe we are going to consider, captures the correlations between energy levels over a wide range of scales. The spectral form factor is defined from an analytical extension of the partition function

\begin{equation}
    SFF = \frac{\left|Z(\beta,t)\right|^2}{|Z(\beta,0)|^2} ~~~~:~~~~ Z(\beta,t) = \text{Tr}\left[e^{-(\beta-it)H}\right]
\end{equation}

{\noindent where $\beta$, t and H are the inverse temperature (which we will always consider equal to 0), time, and the Hamiltonian for a given quantum mechanical system, respectively. Note that we can then express this in terms of the energy eigenvalues of the Hamiltonian:}

\begin{equation}
    Z(\beta,t) = \sum_\omega e^{-(\beta-it)\omega}
\end{equation}

Previous work \cite{cotler_black_2017,PhysRevE.55.4067,Martinez_Azcona_2025} have already proven that in the SFF of RMT and other known chaotic systems one encounter three stages , firstly a dip, then a \textquotedblleft linear ramp \textquotedblright with an approximate slope of 1 on a log-log plot and a saturation point where the SFF becomes constant known as the plateau. This dip-ramp-plateau behaviour is conjectured to be another universal property of quantum chaotic systems.

On the other hand, if the system is integrable we expect the SFF to have a dip and a plateau but lack a ramp.


\subsubsection{Krylov complexity for states}

Apart from the previous more traditional diagnostics, which have been used for a long time, recently Krylov complexity has arisen as a modern tool proposed for probing quantum chaos \cite{Balasubramanian_2022,Parker_2019} most notably again in the context of RMT and also applied to known quantum chaotic systems. Krylov complexity quantifies the spread of a quantum state over a certain subspace of the Hilbert space generated by the Krylov basis. This basis is generated through an algorithm known as Lanczos algorithm, that I will briefly introduce in this section. This new probe offers a complementary perspective to spectral measures and enhances our understanding of quantum chaos.

I will explain how the Krylov basis is constructed following closely the introductory part in \cite{Jeong_2025} which briefly reviews the procedure which is detailed in \cite{Balasubramanian_2022}. If you consider a Hamiltonian system, its dynamic will be governed by the Schrödinger equation:

\begin{equation}
    i\partial_t\ket{\psi(t)} = \hat{H}\ket{\psi(t)}
\end{equation}

This equation is solved using the time-evolution operatior, so you can express the solution as $\ket{\psi(t)}=e^{-iHt}\ket{\psi(0)}$. This can be represent in terms of a power series:

\begin{equation}
    \ket{\psi(t)}=\sum_{n=0}^\infty \frac{(-it)^n}{n!}\ket{\psi_n} ~~~~;~~~~ \ket{\psi_n} = \hat{H}^n\ket{\psi(0)}
\end{equation}

The states $\ket{\psi_n}$ span a subspace of the full Hilbert space known as the Krylov space. However, in general, they are not orthonormal. To construct a proper orthonormal basis of this Krylov space, which we will refer to as the Krylov basis $\ket{K_n}$, we employ the Lanczos algorithm \cite{lanczos_iteration_1950}:

\begin{equation}
    \ket{A_{n+1}} = (\hat{H}-a_n)\ket{K_n}-b_n\ket{K_{n-1}}
\end{equation}

{\noindent where this $a_n$ and $b_n$ are known as the Lanczos coefficients and are given as:}

\begin{equation}
    a_n = \bra{K_n}\hat{H}\ket{K_n} ~~,~~ b_n = \langle A_n | A_n \rangle^{1/2}
\end{equation}

We also need to define the initial conditions and normalization of the Krylov basis:

\begin{equation}\LA{COND}
    \ket{K_0} = \ket{\psi(0)}, ~~~ \ket{K_n} = b_n^{-1}\ket{A_n}, ~~~ b_0=0,
\end{equation}

{\noindent which implies that the Lanczos algorithm can be rewritten as:}

\begin{equation}\LA{LANCZOS}
    \hat{H}\ket{K_n} = a_n\ket{K_n}+b_{n+1}\ket{K_{n+1}}+b_n\ket{K_{n-1}}
\end{equation}

{\noindent where the Lanczos algorithm terminates for n so that $b_n=0$}

With this formulation, you can directly see, that in the Krylov basis the Hamiltonian acquires a tri-diagonal representation:

\begin{equation}
    \bra{K_m}\hat{H}\ket{K_m} = a_n\delta_{m,n} + b_{n+1}\delta_{m,n+1} + b_n\delta_{m,n-1}
\end{equation}

Once we have obtained this orthonormal basis we can express the solution in terms of it:

\begin{equation}
    \ket{\psi(t)} = \sum_n\psi_n(t)\ket{K_n} ~~~~:~~~~ \psi_n(t) = \langle K_n|\psi(t)\rangle
\end{equation}

{\noindent, such that by the normalization condition:}

\begin{equation}
    \sum_n\left|\psi_n(t)\right|^2 = 1
\end{equation}

With this expansion in the Krylov basis one can transform equation (\ref{LANCZOS}) in effectivly a particle hopping in a one-dimensiona chain:

\begin{equation}
    i\partial_t\psi_n(t) = a_n\psi_n(t) + b_{n+1}\psi_{n+1}(t) + b_n\psi_{n-1}(t)
\end{equation}

If you solve this equation, with the initial state we specified in (\ref{COND}), i.e, $\psi_n(0) = \delta_{n0}$, Krylov complexity is then defined as:

\begin{equation}
    C(t)=\sum_n n\left|\psi_n(t)\right|^2
\end{equation}

which quantifies how our initial state that we have specified to be the 0th component of the Krylov basis spreads along the whole basis. For the initial state we use the same as both papers we are following \cite{Jeong_2025,Balasubramanian_2022}, the thermofield double state, that deal with two identical copies of the system at hand:

\begin{equation}
    \ket{\psi(0)} = \frac{1}{\sqrt{Z(\beta,0)}}\sum_n e^{-\frac{\beta E_n}{2}} \ket{n}\otimes\ket{n} ~~~:~~~ \hat{H} \ket{n} = E_n\ket{n}
\end{equation}

In the cases where the system we are considering presents chaotic behaviour we expect to observe a characteristic linear ramp, followed by a peak, a downward slope, and a plateau. This plateau at late times is directly related with the SFF at infinite temperature, i.e $\beta=0$ \cite{Erdmenger_2023}:

\begin{equation}
    \lim_{T\rightarrow\infty}\frac{1}{T}\int_0^T SFF(t)\dd t = \frac{1}{1+2C(t\rightarrow\infty)},
\end{equation}

{\noindent where d is the size of the Hamiltonian. Then at late times, the Krylov complexity will asymptotically tend to $C(t\rightarrow)\approx\frac{d-1}{2}$}

What we expect from our system is that in the chaotic cases we obtain the four stage behaviour that I already mentioned, whereas in the integrable case the peak would disappear, as this peak is proposed as a hallmark of quantum chaos.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{de Sitter spacetimes in Brickwall models}\LA{deSitter_BH}

It was Gerard 't Hooft, who first introduced the Brickwall model \cite{tHooft:1984kcu}, as an elementary exercise to arrive at the entropy of a BH following an statistical mechanics perspective. As we already discussed in the introduction, GR \textquotedblleft breaks\textquotedblright~  at the event horizon of a BH as well as at the cosmological horizon of dS spacetimes, which means that we cannot predict how a field that propagates within those spacetimes works at those exact points. However, nothing prevents us from getting arbitrarily close to this horizon.

Considering this, one could define a \textquotedblleft stretched horizon \textquotedblright and impose a Dirichlet boundary condition in said horizon. The distance between the actual horizon and this stretched one, would work as an UV cut-off of the theory. Normally, when one works with event and cosmological horizons, incoming-wave boundary conditions are considered, i.e, waves just enters and does not come out of this horizons. In this context, one could only obtain quasi-normal modes that decay with time. However, in our Brickwall model, certain configurations of boundary conditions make the obtention of normal modes possible as we will see in the following subsections.

\subsection{Normal mode of probe scalar fields}

During this work, we will only consider scalar fields in favor of simplicity, however, similar results are expected for other types of fields. For example \cite{Jeong_2025} also considers fermionic fields within the BTZ case and results are completely analogous.

\subsubsection{A warm-up: three-dimensional AdS black holes}

Firstly, let's review what \cite{Jeong_2025,Das_2023,das2023fuzzballsrandommatrices} already calculated and analyzed, the normal modes of the scalar field over the BTZ metric, an asymptotically $AdS_{2+1}$ BH. This metric takes the following form\footnote{I am considering the AdS length and the event horizon radius equal to one} in the usual polar coordinates:

\begin{equation}\LA{BTZ_METRIC}
    \dd s^2_{BTZ} = -f(r)\dd t^2 + \frac{\dd r^2}{f(r)} + r^2 \dd\varphi^2
\end{equation}

{\noindent With:}

\begin{equation}
    f(r) = r^2 - 1 ~~~~~:~~~~~ 1 < r < \infty
\end{equation}

{\noindent and $\varphi$ periodic in $2\pi$}

However, we can simplify our future calculations if we consider the following change of coordinates:

\begin{equation}
    r = \sqrt{\frac{1}{1-z}} ~~~~~:~~~~~ \dd r^2 = \frac{\dd z^2}{4(1-z)^3} ~~~~~:~~~~~ 0 < z < 1,
\end{equation}

{\noindent that makes the metric (\ref{BTZ_METRIC}) take this new form:}

\begin{equation}
    \dd s^2_{BTZ} = -\frac{z}{1-z}\dd t^2 + \frac{\dd z^2 }{4z(1-z)^2} + \frac{\dd\varphi^2}{1-z}
\end{equation}

{\noindent In this new coordinate system the event horizon $r\rightarrow 1$ is located in $z\rightarrow 0$.}

From this metric now, we can try to solve the Klein-Gordon equation:

\begin{equation}\LA{KLEIN_GORDON}
    \nabla_\mu\nabla^\mu \Psi =\frac{1}{\sqrt{\abs{g}}}\del_\mu\left(\sqrt{\abs{g}}\del^\mu\Psi\right)= m^2\Psi
\end{equation}

{\noindent To do so, we can consider the following ansatz: }

\begin{equation}
    \Psi(z,\phi,t) = \Phi(z)e^{-i\omega t}e^{iJ\varphi},
\end{equation}

{\noindent i.e, make a Fourier expansion in time and angular variable, where we know that $J\in\mathds{Z}$ because each solution must be periodic in $2\pi$. If we now insert this in equation (\ref{KLEIN_GORDON}) considering only the massless case for simplicity \cite{Jeong_2025,Das_2023,das2023fuzzballsrandommatrices}, we obtain:}

\begin{equation}
    \Phi''(z) + \frac{\Phi'(z)}{z} + \frac{J^2z^2+\w-z(J^2+\w^2)}{4z^2(1-z)^2}\Phi=0,
\end{equation}

which, gladly, has analytical solutions. Indeed, these solution can be expressed in terms of the hypergeometric functions $\hypr$ (see Appendix \ref{HYPR}) as:

\begin{equation}\LA{SOL_BTZ}
    \begin{aligned}
        \Phi(z) = & \calc_1 e^{\frac{\pi\w}{2}} z^{-\frac{i\w}{2}}\hypr\left(\frac{i(J-\w)}{2};-\frac{i(J+\w)}{2};1-i\w;z\right) \\
    + & \calc_2 e^{-\frac{\pi\w}{2}} z^{\frac{i\w}{2}}\hypr\left(-\frac{i(J-\w)}{2};\frac{i(J+\w)}{2};1+i\w;z\right)
\end{aligned}
\end{equation}

We can now consider these solutions around the $AdS$ boundary $z\rightarrow 1$, where the solution takes the form:

\begin{equation}
    \Phi_{bdry}(z) = \calc_1\frac{e^{\frac{i\w}{2}}\Gamma[1-i\w]}{\Gamma\left[1+\frac{i}{2}(J-\w)\right]\Gamma\left[1-\frac{i}{2}(J+\w)\right]} + \calc_2\frac{e^{-\frac{i\w}{2}}\Gamma[1-i\w]}{\Gamma\left[1-\frac{i}{2}(J-\w)\right]\Gamma\left[1+\frac{i}{2}(J+\w)\right]}
\end{equation}

{\noindent And, if we consider the normalizability condition, as in \cite{Jeong_2025,Das_2023,das2023fuzzballsrandommatrices}, $\Phi(1)=0$, it leads us to the following relation between the integration constants:}

\begin{equation}
    \calc_2 = -\calc_1\frac{e^{i\w}\Gamma\left[1-\frac{i}{2}(J-\w)\right]\Gamma\left[1+\frac{i}{2}(J+\w)\right]\Gamma[1-i\w]}{\Gamma\left[1+\frac{i}{2}(J-\w)\right]\Gamma\left[1-\frac{i}{2}(J+\w)\right]\Gamma[1+i\w]}
\end{equation}

Once we have specified this, we can consider our \textit{Brickwall} boundary condition. That is, we consider a \textit{stretched} horizon $z_0$ arbitrarily close to the event horizon ($z=1^+$) and impose a general Dirichlet boundary condition there. In this case:

\begin{equation}\LA{BOUNDARY_BTZ}
    \Phi_{hor}(z_0)\approx \calc_1 e^{\frac{\pi\w}{2}}\left(P_1 z_0^{-\frac{i\w}{2}}+Q_1 z_0^{\frac{i\w}{2}}\right) = {\Phi_0}_J,
\end{equation}

{\noindent where we have used the same naming condition as in \cite{Jeong_2025}:}

\begin{equation}
    P_1 = 1 ~~~~~~ ; ~~~~~~ Q_1 = - \frac{\Gamma\left[1-\frac{i}{2}(J-\w)\right]\Gamma\left[1+\frac{i}{2}(J+\w)\right]\Gamma[1-i\w]}{\Gamma\left[1+\frac{i}{2}(J-\w)\right]\Gamma\left[1-\frac{i}{2}(J+\w)\right]\Gamma[1+i\w]}
\end{equation}

{\noindent and where can check (see Appendix \ref{MODULUSAPEN}) that $\left|Q_1\right|=1$

Moreover we can parametrize the boundary condition as in \cite{Jeong_2025,Das_2023,das2023fuzzballsrandommatrices}:

\begin{equation}
    {\Phi_0}_J = \mu_J e^{i\lambda_J\omega}
\end{equation}

It's important to highlight some things in these parametrization, extensively explained in \cite{das2023fuzzballsrandommatrices}. In the following considerations, we will obtain a quantization condition for the \textit{energy} eigenstates with an explicit $J$ dependence and $n$ dependence coming from the fact that the quantization condition is periodic. It is important to note then, that our \textit{Brickwall} boundary condition is specified a priori so it will only depend in a priori variables of our considerations, i.e $J$. It is true, however, that with our current parametrization $\lambda_J$ depends on $n$ because we wanted to include $\w$ in the phase of the boundary condition to ease our following calculations\footnote{As the reader must be now thinking, it is true that in this case then the notation should be $\lambda_{J,n}$, but we will not do so to maintain homogeneity with previous work}. However, if we were to reparametrize our boundary condition following $\lambda_J \rightarrow \lambda_J/\w$ then, $\lambda_j$ and $\mu_J$ would only depend on J.

If we now rearrange equation (\ref{BOUNDARY_BTZ}), we can write:

\begin{equation}\LA{QUANTIZATION_BTZ}
    e^{i\theta_Q} = \mu_J e^{i\left(\lambda_J\w + \frac{\theta}{2}\right)} - e^{i\theta}
\end{equation}

{\noindent where we have considered:}

\begin{equation}
    \theta = \Arg\left[z_0^{i\omega}\right] ~~~~~~;~~~~~~\theta_Q = -\Arg\left[Q_1\right] ~~~~~~;~~~~~~ \calc_1Q_1e^{\frac{\pi\w}{2}}=1
\end{equation}

From this relation we can extract two different considerations. The first one comes from equating the modulus of the two sides of the equation:

\begin{equation}\LA{MODULUS_BTZ}
    \mu_J = 2\cos\left(\lambda_J\w - \frac{\theta}{2}\right)
\end{equation}

{\noindent And the second one comes from equating the phases of both sides:}
\begin{equation}
    \left.\begin{aligned}
        \cos{\theta_Q} &= \cos{\left(2\lambda_J\w\right)}\\
        \sin{\theta_Q} &= \sin{\left(2\lambda_J\w\right)}
    \end{aligned}\right\}\Longrightarrow \theta_Q = 2\lambda_J\omega +2\pi n ~~~~:~~~~ n\in\mathds{Z}
\end{equation}

In the end then, we just need to specify the values of $\lambda_J$ and $\mu_J$ and solve the quantization condition. Following \cite{Jeong_2025,Das_2023,das2023fuzzballsrandommatrices} we are going to extract the values of $\lambda_J$ from a Gaussian distribution, and fix its mean value so that $\mu_J=2$. This can be accomplished, considering equation (\ref{MODULUS_BTZ}), if we fix:

\begin{equation}
    \langle\lambda_J\rangle = \half\log z_0
\end{equation}

{\noindent Additionally, again as in \cite{Jeong_2025,Das_2023,das2023fuzzballsrandommatrices} the $\lambda_J$-variance is going to be of the form $\sigma = \sigma_o/\sqrt{J}$. Taking this into account, we can obtain the normal modes that we have plotted in Figure \ref{NORMAL_BTZ}, where we have considered two extreme examples $\sigma_0=0$ and $\sigma_0=2$}.

\begin{figure}
    \centering
    \subcaptionbox{$\sigma_0=0$}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[
                width=0.44\textwidth,
                height=5.5cm,
                mark size=1pt,
                ytick={0.00015708,0.00015710,0.00015712,0.00015714,0.00015716,0.00015718},
                y tick label style= {
                    /pgf/number format/.cd,
                    fixed,
                    fixed zerofill,
                    precision=4,
                    /tikz/.cd},
                xlabel=J,
                xmin=-20,
                xmax=410,
                ylabel=$\w$,
                y label style = {rotate = -90},
                ymin=0.00015707,
                ymax=0.00015718
                ]
                \addplot+ [only marks] table
                {etc/data/BTZ_SIGMA0.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{1.7cm}
    \subcaptionbox{$\sigma_0=2$}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[
                width=0.44\textwidth,
                height=5.5cm,
                mark size=1pt,
                ytick={0.00015708,0.00015710,0.00015712,0.00015714,0.00015716,0.00015718},
                y tick label style= {
                    /pgf/number format/.cd,
                    fixed,
                    fixed zerofill,
                    precision=4,
                    /tikz/.cd},
                xlabel=J,
                xmin=-20,
                xmax=410,
                ylabel=$\w$,
                y label style = {rotate = -90},
                ymin=0.00015707,
                ymax=0.00015718
                ]
                \addplot+ [only marks] table
                {etc/data/BTZ_SIGMA2.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Normal Modes of a massless scalar field over the BTZ spacetime with the normalization condition $\Phi(0)=0$ and the Brickwall boundary condition $\Phi(z_0)=\mu_Je^{i\lambda_J\omega}$, where we extract the values of $\lambda_J$ from a Gaussian distribution with mean value $\langle\lambda_J\rangle=\half\log{z_0}\approx 10^{-4}$ and a variance $\sigma=\sigma_0/\sqrt{J}$}\LA{NORMAL_BTZ}
\end{figure}

\subsubsection{Empty dS spacetime}

Considering what we reviewed in the previous subsection about the already performed calculation of the normal modes of a scalar field over the BTZ BH, it is quite straightforward to use the same considerations to obtain the normal modes of scalar fields over the de Sitter static patch\footnote{Mostly because as its metric can be obtained applying a spacetime isomorphism to the BTZ metric} \cite{Anninos_2012} .

The metric of the $dS_{d+1}$ static patch\footnote{I am considering the dS length and the cosmological horizon radius equal to one} in the usual spherical coorinates takes the following form:

\begin{equation}
    \dd s^2_{d+1} = -h(r)\dd t^2 + \frac{\dd r^2}{h(r)}+r^2\dd\Omega_{d-1}^2
\end{equation}

{\noindent With:}

\begin{equation}
    h(r) = 1 - r^2 ~~~~~:~~~~~ 0 < r < 1
\end{equation}

{\noindent and $\dd\Omega^2_{d-1}$ the usual metric of the unit $(d-1)$-sphere.}

From this metric now, we will also try to solve equation (\ref{KLEIN_GORDON}), considering the following ansatz:

\begin{equation}
    \Psi(r,\Omega,t) = \Phi(r)e^{-i\w t}Y(\Omega),
\end{equation}

{\noindent i.e, make a Fourier expansion in energy and an expansion in (d-1)-dimensional spherical harmonics of the angular part (See Appendix \ref{HYPR}). If we now insert this in equation (\ref{KLEIN_GORDON}), again only considering the massless case, we obtain:}

\begin{equation}
    \begin{aligned}
        \inv{r^{d-1}}\frac{\dd}{\dd r}\left(hr^{d-1}\frac{\dd\Phi}{\dd r}\right) +\left[\frac{l(l+d-2)}{r^2}-\frac{\w^2}{h}\right]\Phi &= 0,\\
        \left(r^2-1\right)\Phi''+\left[\frac{1-d}{r}+r(1+d)\right]\Phi'+\left[\frac{l(l+d-2)}{r^2}-\frac{\w^2}{1-r^2}\right]\Phi &= 0,
    \end{aligned}
\end{equation}

{\noindent which again has an analytical solution in terms of hypergeometric functions $\hypr$:}

\begin{equation}\LA{SOL_STATIC}
    \begin{aligned}
        \Phi(r) = \calc_1(1-r^2)^{-i\w/2}r^l&\hypr\left[\half\left(l-i\w\right),\half\left(d+l-i\w\right),\frac{d}{2}+l,r^2\right) \\
        + \calc_2(1-r^2)^{-i\w/2}r^{2-d-l}&\hypr\left(1-\half\left(l+i\w\right),1-\half\left(d+l+i\w\right),2-\frac{d}{2}-l,r^2\right)
    \end{aligned}
\end{equation}

Now, we can consider these solutions around the origin $r\rightarrow0$, and impose that this solution needs to be regular at that point:

\begin{equation}
    \Phi_{bdry}(r) = \calc_1 r^l\left[1+\frac{l(d+l)-\w^2}{2(d+2l)}r^2 + O(r^3)\right] + \calc_2r^{-d-l}\left[r^2+O(r^3)\right],
\end{equation}

{\noindent which then leads to imposing:}

\begin{equation}
    \calc_2 = 0.
\end{equation}

{\noindent That is, the whole second solution is non-regular at the origin.}

Again, once we have specified this, we can apply the Brickwall boundary condition. In this case, we will consider a stretched horizon $r_0$ arbitrarily close to the cosmological horizon ($r=1^-$) and impose a general Dirichlet boundary condition there. Note that we will use a pretty similar notation to the one in the previous section:

\begin{equation}
    \Phi(r_0)\approx\pi \csch\left(\pi\w\right)\Gamma\left(\frac{d}{2}+l\right) \frac{\calc_1}{\w}\left\{P_2(2-2r_0)^{-\frac{i\w}{2}}+Q_2(2-2r_0)^{\frac{i\w}{2}}\right\}= {\Phi_0}_l,
\end{equation}

{\noindent with:}

\begin{equation}\LA{STATIC_BOUNDARY}
    \begin{gathered}
        P_2 =\frac{1}{\Gamma\left[\frac{l+i\w}{2}\right]\Gamma\left[\frac{d+l+i\w}{2}\right]\Gamma\left[-i\omega\right]}\\
        Q_2=\frac{1}{\Gamma\left[\frac{l-i\w}{2}\right]\Gamma\left[\frac{d+l-i\w}{2}\right]\Gamma\left[i\omega\right]} 
    \end{gathered}
\end{equation}

{\noindent and where we can check (see Appendix \ref{MODULUSAPEN}) that $\abs{Q_2}=\abs{P_2}$. }

Lastly, using a similar parametrization to the one on the previous subsection we can rearrange equation (\ref{STATIC_BOUNDARY}) and write:

\begin{equation}
    e^{i(\theta_P-\theta_Q)} = \mu_l e^{i\left(\lambda_l\w + \frac{\theta}{2}\right)}-e^{i\theta},
\end{equation}

{\noindent with:}

\begin{equation}
    \begin{gathered}
        \theta=\Arg\left[(2-2r_0)^{i\w}\right] ~~~~~~;~~~~~~ \theta_Q=\Arg\left[Q_2\right] ~~~~~~;~~~~~~ \theta_P=\Arg\left[P_2\right]\\
        \pi \csch\left(\pi\w\right)\Gamma\left(\frac{d}{2}+l\right) \frac{\calc_1Q_2}{\w} = 1
    \end{gathered}
\end{equation}

This relation, analogously to what we discussed about equation \ref{QUANTIZATION_BTZ}, can be translated into:

\begin{equation}
    \begin{gathered}
        \mu_l = 2\cos\left(\lambda_l\w - \frac{\theta}{2}\right)\\
        \left.\begin{aligned}
            \cos{\theta_P-\theta_Q} &= \cos{\left(2\lambda_l\w\right)}\\
            \sin{\theta_P-\theta_Q} &= \sin{\left(2\lambda_l\w\right)}
        \end{aligned}\right\}\Longrightarrow \theta_Q = 2\lambda_l\omega +2\pi n ~~~~:~~~~ n\in\mathds{Z}
    \end{gathered}
\end{equation}

{\noindent So we can just do the same procedure, fixing the mean value to $\langle\lambda_l\rangle = \half\log\left(2-2r_0\right)$ and the $\lambda_l$-variance to $\sigma=\sigma_0/\sqrt{l}$. Taking, then, this into account, we can obtain the normal modes plotted in Figure \ref{NORMAL_STATIC}, where we have considered $d=3$.}

\begin{figure}
    \centering
    \subcaptionbox{$\sigma_0=0$}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[
                width=0.44\textwidth,
                height=5.5cm,
                mark size=1pt,
                ytick={0.00015708,0.00015710,0.00015712,0.00015714,0.00015716,0.00015718},
                y tick label style= {
                    /pgf/number format/.cd,
                    fixed,
                    fixed zerofill,
                    precision=4,
                    /tikz/.cd},
                xlabel=l,
                xmin=-20,
                xmax=410,
                ylabel=$\w$,
                y label style = {rotate = -90},
                ymin=0.00015707,
                ymax=0.00015718
                ]
                \addplot+ [only marks] table
                {etc/data/STATIC_SIGMA0.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{1.7cm}
    \subcaptionbox{$\sigma_0=2$}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[
                width=0.44\textwidth,
                height=5.5cm,
                mark size=1pt,
                ytick={0.00015708,0.00015710,0.00015712,0.00015714,0.00015716,0.00015718},
                y tick label style= {
                    /pgf/number format/.cd,
                    fixed,
                    fixed zerofill,
                    precision=4,
                    /tikz/.cd},
                xlabel=l,
                xmin=-20,
                xmax=410,
                ylabel=$\w$,
                y label style = {rotate = -90},
                ymin=0.00015707,
                ymax=0.00015718
                ]
                \addplot+ [only marks] table
                {etc/data/STATIC_SIGMA2.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Normal Modes of a massless scalar field over the static patch of the $dS_{3+1}$ spacetime with the normalization condition $\Phi(0)=0$ and the Brickwall boundary condition $\Phi(r_0)=\mu_le^{i\lambda_l\omega}$, where we extract the values of $\lambda_l$ from a Gaussian distribution with mean value $\langle\lambda_l\rangle=\half\log\left(2-2r_0\right)\approx 10^{-4}$ and a variance $\sigma=\sigma_0/\sqrt{l}$}\LA{NORMAL_STATIC}
\end{figure}


%%
%%}{\Gamma\left[\frac{l+i\w}{2}\right]\Gamma\left[\frac{d+l+i\w}{2}\right]\Gamma\left[-i\omega\right]}

\subsection{Quantum chaos signatures with stretched \textit{cosmological} horizons}
\subsubsection{Level spacing distribution and spectral form factor}
\begin{figure}[ht]
    \centering
    \subcaptionbox{$\sigma_0=0$ (Delta-like)\vspace*{.25cm}}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[ybar,width=0.45\textwidth,height=0.45*7/10*\textwidth,
                xmin=-0.05,
                xmax=4.05,
                ymin=0,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=s,
                ylabel=p(s),
                y label style = {rotate = -90}]
                \addplot+ [bar width=0.1, black!50!white, draw=black]
                table {etc/data/STATIC_HISTOGRAM0.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{2cm}
    \subcaptionbox{$\sigma_0=0.017$ (GSE)}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[ybar,width=0.45\textwidth,height=0.45*7/10*\textwidth,
                xmin=-0.05,
                xmax=4.05,
                ymin=0,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=s,
                ylabel=p(s),
                y label style = {rotate = -90}]
                \addplot+ [bar width=0.1, red!50!white, draw=black]
                table {etc/data/STATIC_HISTOGRAM0017.dat};
                \addplot [
                    black,
                    sharp plot,
                    line width =1]
                table {etc/data/GSE.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \subcaptionbox{$\sigma_0=0.024$ (GUE)\vspace*{.25cm}}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[ybar,width=0.45\textwidth,height=0.45*7/10*\textwidth,
                xmin=-0.05,
                xmax=4.05,
                ymin=0,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=s,
                ylabel=p(s),
                y label style = {rotate = -90}]
                \addplot+ [bar width=0.1, blue!50!white, draw=black]
                table {etc/data/STATIC_HISTOGRAM0024.dat};
                \addplot [
                    black,
                    sharp plot,
                    line width =1]
                table {etc/data/GUE.dat}; 
            \end{axis}
        \end{tikzpicture}
    }
    \hspace{2cm}
    \subcaptionbox{$\sigma_0=0.030$ (GOE)}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[ybar,width=0.45\textwidth,height=0.45*7/10*\textwidth, xmin=-0.05,
                xmax=4.05,
                ymin=0,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=s,
                ylabel=p(s),
                y label style = {rotate = -90}]
                \addplot+ [bar width=0.1, green!50!white, draw=black]
                table {etc/data/STATIC_HISTOGRAM0030.dat};
                \addplot [
                    black,
                    sharp plot,
                    line width =1]
                table {etc/data/GOE.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \subcaptionbox{$\sigma_0=0.5$ (POISSON)}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{axis}[ybar,width=0.45\textwidth,height=0.45*7/10*\textwidth,
                xmin=-0.05,
                xmax=4.05,
                ymin=0,
                xtick pos=bottom,
                ytick pos=left,
                xlabel=s,
                ylabel=p(s),
                y label style = {rotate = -90}]
                \addplot+ [bar width=0.1, gray!50!white, draw=black]
                table {etc/data/STATIC_HISTOGRAM05.dat};
                \addplot [
                    black,
                    sharp plot,
                    line width =1]
                table {etc/data/POISSON.dat};
            \end{axis}
        \end{tikzpicture}
    }
    \caption{Level spacing distributions of the normal modes, considering a disorder average. The solid lines are given by their respective analytic distribution}
\end{figure}

\begin{figure}[ht]
    \centering
    \subcaptionbox{$\sigma_0=0.017$\vspace*{.25cm}}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{loglogaxis}[
                width=0.45\textwidth,
                height=0.45*7/10*\textwidth,
                xtick pos=bottom,
                xmin=7e6,
                xmax=2e13,
                ytick pos=left,
                xlabel=t,
                ylabel=SFF(t)]
                \addplot+ [draw=red, mark=none]
                table {etc/data/SFF_STATIC_SIGMA0017.dat};
            \end{loglogaxis}
        \end{tikzpicture}
    }
    \hspace{2cm}
    \subcaptionbox{$\sigma_0=0.024$}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{loglogaxis}[
                width=0.45\textwidth,
                height=0.45*7/10*\textwidth,
                xtick pos=bottom,
                xmin=7e6,
                xmax=2e13,
                ytick pos=left,
                xlabel=t,
                ylabel=SFF(t)]
                \addplot+ [draw=blue, mark=none]
                table {etc/data/SFF_STATIC_SIGMA0024.dat};
            \end{loglogaxis}
        \end{tikzpicture}
    } 
    \subcaptionbox{$\sigma_0=0.030$}
    {
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{loglogaxis}[
                width=0.45\textwidth,
                height=0.45*7/10*\textwidth,
                xtick pos=bottom,
                xmin=7e6,
                xmax=2e13,
                ytick pos=left,
                xlabel=t,
                ylabel=SFF(t)]
                \addplot+ [draw=green, mark=none]
                table {etc/data/SFF_STATIC_SIGMA0030.dat};
            \end{loglogaxis}
        \end{tikzpicture}
    }
    \hspace{2cm}
    \subcaptionbox{$\sigma_0=0.5$}
    { 
        \begin{tikzpicture}[trim axis left, trim axis right]
            \begin{loglogaxis}[
                width=0.45\textwidth,
                height=0.45*7/10*\textwidth,
                xtick pos=bottom,
                xmin=7e6,
                xmax=2e13,
                ytick pos=left,
                xlabel=t,
                ylabel=SFF(t)]
                \addplot+ [draw=black, mark=none]
                table {etc/data/SFF_STATIC_SIGMA05.dat};
            \end{loglogaxis}
        \end{tikzpicture}
    } 
    \caption{Spectral Form Factor of the scalar fields considering a disorder-average}
\end{figure}

\subsubsection{Krylov complexity}

\begin{figure}[ht]
    \centering
        \begin{tikzpicture}
            \begin{axis}[width=0.8\textwidth,height=0.8*7/10*\textwidth,
                ymin=0,
                xmin=0,
                xmax=4e11,
                xlabel=t,
                ylabel=C(t)/d,
                y label style = {rotate = -90},
                scaled ticks = false,
                xtick={0, 1e11, 2e11, 3e11, 4e11},
                minor x tick num = 8,
                minor y tick num = 8]
                \addplot+ [black!70!white,line width=2,mark=none]
                table {etc/data/KRYLOV_STATIC0.dat};
                \addplot+ [red!70!white,line width=2,mark=none]
                table {etc/data/KRYLOV_STATIC0017.dat};
                \addplot+ [blue!70!white,line width=2,mark=none]
                table {etc/data/KRYLOV_STATIC0024.dat};
                \addplot+ [green!70!white,line width=2,mark=none]
                table {etc/data/KRYLOV_STATIC0030.dat};
                \addplot+ [gray!70!white,line width=2,mark=none]
                table {etc/data/KRYLOV_STATIC05.dat};
            \end{axis}
        \end{tikzpicture}
        \caption{Krylov complexity of the normal modes when $\sigma=0,~ 0.017,~ 0.024,~ 0.030,~ 0.5$ (black, red, blue, green, black)}
\end{figure}

\subsubsection{Results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%    
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusions}\label{label4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\appendix

\section{Level Separation Distribution of the GOE Ensemble in \texorpdfstring{$2\times 2$}{TEXT} case}\LA{LSD}

\section{Hypergeometric Function}\LA{HYPR}

The solutions to scalar field normal modes in equations (\ref{SOL_BTZ}), (\ref{SOL_STATIC}) are written in terms of the hypergeometric function $\hypr(a,b;c;z)$ which is defined as:

\begin{equation}
    \hypr(a,b;c;z) = \sum^{\infty}_{n=0} \frac{(a)_n(b)_n}{(c)_n}\frac{z^n}{n!} ~~~~~~:~~~~~~ \abs{z} < 1
\end{equation}

{\noindent in terms of the Pochhammer symbol $(x)_n$, defined by: }

\begin{equation}
    (x)_n=\left\{
        \begin{aligned}
            &1 &n=0 \\
            &x(x+1)...(x+n-1) ~~~~ &n>0
        \end{aligned}
        \right.
\end{equation}

\section{Modulus of \texorpdfstring{$Q_1$}{TEXT}, \texorpdfstring{$P_2$}{TEXT} and \texorpdfstring{$Q_2$}{TEXT}}\LA{MODULUSAPEN}

During Section \ref{deSitter_BH} we define the quantities:

\begin{equation}
    \begin{aligned}
        Q_1 &= - \frac{\Gamma\left[1-\frac{i}{2}(J-\w)\right]\Gamma\left[1+\frac{i}{2}(J+\w)\right]\Gamma[1-i\w]}{\Gamma\left[1+\frac{i}{2}(J-\w)\right]\Gamma\left[1-\frac{i}{2}(J+\w)\right]\Gamma[1+i\w]}\\
        P_2 &=\frac{1}{\Gamma\left[\frac{l+i\w}{2}\right]\Gamma\left[\frac{d+l+i\w}{2}\right]\Gamma\left[-i\omega\right]} \\
        Q_2 &=\frac{1}{\Gamma\left[\frac{l-i\w}{2}\right]\Gamma\left[\frac{d+l-i\w}{2}\right]\Gamma\left[i\omega\right]} 
    \end{aligned}
\end{equation}

{\noindent It is easy to prove that:}

\begin{equation}\LA{MODULUS}
    \abs{Q_1} = 1 ~~~~~~;~~~~~~ \abs{P_2} = \abs{Q_2}
\end{equation}

{\noindent To do so, we just need to take into account the fact that:}

\begin{equation}
    \Gamma(\overline{z})=\overline{\Gamma(z)},
\end{equation}

{\noindent which implies that:}

\begin{equation}
    \abs{\Gamma(\overline{z})} = \abs{\overline{\Gamma(z)}} = \abs{\Gamma(z)}
\end{equation}

{\noindent directly proving equation (\ref{MODULUS})}

\newpage

\printbibliography

\end{document}



